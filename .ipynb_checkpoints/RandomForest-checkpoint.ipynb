{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip as gz\n",
    "from math import log, sqrt, pi, exp\n",
    "import Queue\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pca(data, k_features):\n",
    "    '''name:         pca\n",
    "       description:  function takes an original data set an makes the following transformations: \n",
    "                     the data is centered about the origin; the covariance is then calculated; \n",
    "                     the eigenvalues and eigenvectors of the covariance are found; \n",
    "                     the original data is the projected onto the k eigenvectors in descending order \n",
    "                     of their eigenvalues, creating a new N x K matrix of k principal components\n",
    "       dependencies: none\n",
    "       inputs:       data - is an N x K matrix with the rows representing observations and columns representing features\n",
    "                     k_features - is an integer representing the number of principal components or features to keep\n",
    "       outputs:      reduced_data - an N x k_features matrix \n",
    "    '''\n",
    "    # if number of features is equal to data features return the data\n",
    "    if k_features == data.shape[1]: return data\n",
    "    \n",
    "    # check 0 < k_features <= number of features\n",
    "    if k_features > 0 and k_features < data.shape[1]:\n",
    "      \n",
    "        # center the data and calculate the covariance matrix (sigma)\n",
    "        sigma = np.cov(data.T)\n",
    "        \n",
    "        # get the eigenvectors of sigma\n",
    "        eigen_vecs, _, _ = np.linalg.svd(sigma)\n",
    "        \n",
    "        # create an empty matrix to hold dimensionally reduced data\n",
    "        reduced_data = np.empty((data.shape[0], k_features))\n",
    "\n",
    "        # for each observation x, project x onto eigenvectors\n",
    "        for observation_idx in range(data.shape[0]):\n",
    "            reduced_data[observation_idx] = np.dot(eigen_vecs[:,:k_features].T, data[observation_idx,:][:,np.newaxis])[:,np.newaxis].T\n",
    "            \n",
    "        # return dimensionally reduced data\n",
    "        return reduced_data\n",
    "    \n",
    "    # print error message\n",
    "    print ('ERROR: 0 < k_features < %i') % data.shape[1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cases(data, cases):\n",
    "    '''name:         get_cases\n",
    "       description:  takes and N x K matrix and returns a N' x K martix,\n",
    "                     where the data is only the date with labels matching the specifiued cases\n",
    "       dependencies: None\n",
    "       inputs:       data - N x K matrix of data with labels in col 0\n",
    "                     cases - tuple of labels to be kept\n",
    "       outputs:      None\n",
    "    '''\n",
    "    # get logical array by examining the colmun where the labels match the cases\n",
    "    logical_array = np.logical_or.reduce([data[:,0] == case for case in cases])\n",
    "    \n",
    "    # return the new data matrix with binary labels\n",
    "    return data[logical_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_zip_code_data(filename, cases, num_features):\n",
    "    '''name:         clean_zip_code_data\n",
    "       description:  opens a gziped file and extracts the specified cases, \n",
    "                     converts the two cases to binary and reduces the number of features using PCA\n",
    "       dependencies: get_cases\n",
    "       inputs:       filename - name of file\n",
    "                     cases - a tuple of two digits\n",
    "       outputs:      returns N x K matrix of binary labeled (column zero) zipcode data\n",
    "    '''\n",
    "    # read the zip code data\n",
    "    with gz.open(filename) as f:\n",
    "        train_data = np.loadtxt(f)\n",
    "\n",
    "    # filter out specify cases\n",
    "    train_data = get_cases(train_data, cases)\n",
    "\n",
    "    # split labels and features\n",
    "    X_train = train_data[:,1:]\n",
    "    y_train = train_data[:,0][:,np.newaxis]\n",
    "    \n",
    "    # convert labels to binary\n",
    "    y_train = np.where(y_train == cases[0], 0, 1)\n",
    "\n",
    "    #exctract features using pca\n",
    "    X_train = pca(X_train, num_features)\n",
    "    \n",
    "    # return data with labels in column zero\n",
    "    return np.hstack((y_train,X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class node(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.randomVector = None\n",
    "        self.mean_pos = None\n",
    "        self.mean_neg = None\n",
    "        self.std_pos = None\n",
    "        self.std_neg = None\n",
    "        self.score = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent_score = None\n",
    "        \n",
    "    def set_randomVec(self, size):\n",
    "        '''name:         set_randomVec\n",
    "           description:  Creates a randmom unit vector\n",
    "           dependencies: None\n",
    "           inputs:       size - is the number of feature in the data\n",
    "           outputs:      None\n",
    "        '''\n",
    "        # create a random vector\n",
    "        x = np.random.rand(size)\n",
    "        \n",
    "        # normalize x and set data member\n",
    "        self.randomVector = (x / np.linalg.norm(x))[:,np.newaxis]\n",
    "        \n",
    "    def set_gaussian_variables(self, data):\n",
    "        \n",
    "        # set positive gaussian variables\n",
    "        self.mean_pos = np.mean(data[data[:,0] == 0][:,1])\n",
    "        self.std_pos = np.std(data[data[:,0] == 0][:,1]) if np.std(data[data[:,0] == 0][:,1]) != 0 else 0.0001\n",
    "        \n",
    "        # set negative gaussian variables\n",
    "        self.mean_neg = np.mean(data[data[:,0] == 1][:,1])\n",
    "        self.std_neg = np.std(data[data[:,0] == 1][:,1]) if np.std(data[data[:,0] == 1][:,1]) != 0 else 0.0001\n",
    "            \n",
    "    def set_score(self, predicted_labels, actual_labels):\n",
    "        # set score to be the percent correctly classified\n",
    "        self.score = 1 - (np.sum(np.absolute(np.subtract(predicted_labels, actual_labels))) / actual_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class random_forest(object):\n",
    "    \n",
    "    def __init__(self, num_trees=11, stoping_condition=5):\n",
    "        self.num_trees = num_trees\n",
    "        self.trees = []\n",
    "        self.stoping_condition = stoping_condition\n",
    "        self.predicitions = None\n",
    "\n",
    "    def __create_tree(self, data):\n",
    "        '''name: \n",
    "           description:\n",
    "           dependencies:\n",
    "           inputs:\n",
    "           outputs:\n",
    "        '''\n",
    "        # get nmuber of features\n",
    "        num_features = data.shape[1] - 1\n",
    "        \n",
    "        # create queue\n",
    "        queue = Queue.Queue()\n",
    "        \n",
    "        # create root node and add to queue\n",
    "        root = node()\n",
    "        queue.put((root, data))\n",
    "        \n",
    "        # while queue in not empty\n",
    "        while not queue.empty():\n",
    "        \n",
    "            # get current node\n",
    "            current_tupple = queue.get()\n",
    "            current_node = current_tupple[0]\n",
    "            current_data = current_tupple[1]\n",
    "            \n",
    "            # get number of observations\n",
    "            num_observation = current_data.shape[0]\n",
    "            \n",
    "            # create empty vector for predicted labels\n",
    "            predicted_labels = np.empty(num_observation)\n",
    "        \n",
    "            # create/set nodes random vector\n",
    "            current_node.set_randomVec(num_features)\n",
    "            \n",
    "            # create an empty matrix for the projections and project observations onto random vec\n",
    "            projected_data = np.empty(num_observation)\n",
    "            for projection in range(num_observation):\n",
    "                projected_data[projection] = np.dot(current_data[projection,1:][np.newaxis,:], current_node.randomVector)\n",
    "            \n",
    "            # set the mean and variance for both positive and negative projected data\n",
    "            current_node.set_gaussian_variables(np.hstack((current_data[:,0][:,np.newaxis], projected_data[:,np.newaxis])))\n",
    "            \n",
    "            # for each observation\n",
    "            for observation_idx in range(num_observation):\n",
    "            \n",
    "                # caculate negative and positive probability\n",
    "                pos_prob = (1 / (current_node.std_pos * sqrt(2 * pi))) * exp(-((projected_data[observation_idx] - current_node.mean_pos)**2 / (2 * current_node.std_pos**2)))\n",
    "                neg_prob = (1 / (current_node.std_neg * sqrt(2 * pi))) * exp(-((projected_data[observation_idx] - current_node.mean_neg)**2 / (2 * current_node.std_neg**2)))\n",
    "                \n",
    "                # classify observation\n",
    "                predicted_labels[observation_idx] = 0 if pos_prob > neg_prob else 1\n",
    "                \n",
    "            # caculate/set nodes score\n",
    "            current_node.set_score(predicted_labels, current_data[:,0])\n",
    "            \n",
    "            # combine predicted labels with data\n",
    "            new_data = np.hstack((predicted_labels[:, np.newaxis], current_data))\n",
    "            \n",
    "            # if the number of observations is greater than five and the current score isn't prefect\n",
    "            if current_node.score != current_node.parent_score: #and current_node.score > 0.1:\n",
    "                \n",
    "                if new_data[new_data[:,0] == 0][:,1:].shape[0] > self.stoping_condition:\n",
    "\n",
    "                    # create left node and add node and data predicted positive to queue\n",
    "                    current_node.left = node()\n",
    "                    current_node.left.parent_score = current_node.score\n",
    "                    queue.put((current_node.left, new_data[new_data[:,0] == 0][:,1:]))\n",
    "                    \n",
    "                if new_data[new_data[:,0] == 1][:,1:].shape[0] > self.stoping_condition:\n",
    "\n",
    "                    # create right node and add node and data predicted negative to queue\n",
    "                    current_node.right = node()\n",
    "                    current_node.right.parent_score = current_node.score\n",
    "                    queue.put((current_node.right, new_data[new_data[:,0] == 1][:,1:]))\n",
    "\n",
    "        # return root of tree\n",
    "        return root\n",
    "    \n",
    "    def train(self, data):\n",
    "        '''name: \n",
    "           description:\n",
    "           dependencies:\n",
    "           inputs:\n",
    "           outputs:\n",
    "        '''\n",
    "        # create specified number of trees\n",
    "        for tree in range(self.num_trees):\n",
    "            \n",
    "            #if (tree + 1 ) % 10 == 0:\n",
    "                #print 'creating tree ', tree + 1\n",
    "                #sys.stdout.flush()\n",
    "            \n",
    "            # add each tree to list of trees\n",
    "            self.trees.append(self.__create_tree(data))\n",
    "    \n",
    "    def predict(self, data, score=0.9):\n",
    "        '''name: \n",
    "           description:\n",
    "           dependencies:\n",
    "           inputs:\n",
    "           outputs:\n",
    "        '''\n",
    "        # create empty vector for the predictions\n",
    "        self.predicitions = np.empty(data.shape[0])\n",
    "        \n",
    "        # loop and grab each observation\n",
    "        for observationIndex in range(data.shape[0]):\n",
    "            \n",
    "            # create a temp list to store the predictions for that observation in each tree\n",
    "            temp_preds = []\n",
    "            \n",
    "            # grab each tree to predict in the current observation\n",
    "            for tree in self.trees:\n",
    "            \n",
    "                # predict on the current observation with the current tree\n",
    "                temp_preds.append(self.__initial_prediction(data[observationIndex,1:][np.newaxis,:], tree, score))\n",
    "                \n",
    "            # count the total number of positive and negative\n",
    "            self.predicitions[observationIndex] = 0 if (sum(temp_preds) < self.num_trees / 2) else 1\n",
    "    \n",
    "    def __initial_prediction(self, observation, tree, score):\n",
    "        '''name: \n",
    "           description:\n",
    "           dependencies:\n",
    "           inputs:\n",
    "           outputs:\n",
    "        '''\n",
    "        # iterate through the tree while the tree score is less than or equal to score\n",
    "        visitor = tree\n",
    "        \n",
    "        classifying = True\n",
    "        \n",
    "        # loop till wanted score is greater than training score\n",
    "        # visitors score can become None which will always evalueat to less than \n",
    "        while classifying :\n",
    "            \n",
    "            \n",
    "            # project the data into the random vector\n",
    "            projected_data = np.dot(observation, visitor.randomVector)\n",
    "            \n",
    "            # caculate negative and positive probability\n",
    "            pos_prob = (1 / (visitor.std_pos * sqrt(2 * pi))) * exp(-((projected_data - visitor.mean_pos)**2 / (2 * visitor.std_pos**2)))\n",
    "            neg_prob = (1 / (visitor.std_neg * sqrt(2 * pi))) * exp(-((projected_data - visitor.mean_neg)**2 / (2 * visitor.std_neg**2)))\n",
    "            \n",
    "            classification = 0 if pos_prob > neg_prob else 1\n",
    "            \n",
    "            visitor = visitor.left if classification == 0 else visitor.right\n",
    "            \n",
    "            classifying = True if visitor and visitor.score <= score else False\n",
    "                \n",
    "        return classification\n",
    "        \n",
    "    def score(self,y):\n",
    "        '''name: \n",
    "           description:\n",
    "           dependencies:\n",
    "           inputs:\n",
    "           outputs:\n",
    "        '''\n",
    "        return 1 - (np.sum(np.absolute(np.subtract(self.predicitions, y))) / y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "creating tree  10\n",
      "Cases = 3, 5 Score = 0.613497\n",
      "(0, 8)\n",
      "creating tree  10\n",
      "Cases = 0, 8 Score = 0.592025\n",
      "(7, 9)\n",
      "creating tree  10\n",
      "Cases = 7, 9 Score = 0.634969\n"
     ]
    }
   ],
   "source": [
    "cases = [(3,5),(0,8),(7,9)]\n",
    "\n",
    "for case in cases:\n",
    "    # specify file name, cases and number of features \n",
    "    data_train = clean_zip_code_data('../Data/zip.train.gz', case, 256)\n",
    "    data_test = clean_zip_code_data('../Data/zip.test.gz', case, 256)\n",
    "\n",
    "    # create a random forest\n",
    "    rf = random_forest(num_trees=501, stoping_condition=5)\n",
    "\n",
    "    # train the random forest\n",
    "    rf.train(data_train)\n",
    "\n",
    "    # get predictions\n",
    "    rf.predict(data_test, score=0.9)\n",
    "\n",
    "    # get score\n",
    "    print \"Cases = %i, %i Score = %f\" % (case[0],case[1], rf.score(data_test[:,0]) )\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
